# Ollama的phi3:latest模型
```
messages = [
    {"role": "system", "content": "你是一个简洁、准确的助手"}
]

def ask(msg):
    global messages

    # 1️⃣ 加入用户输入
    messages.append({"role": "user", "content": msg})

    # 2️⃣ 调用模型
    response = client.chat.completions.create(
        model="phi3:latest",
        messages=messages,   # ✅ 关键：传整个历史
        stream=True
    )

    # 3️⃣ 收集模型回复
    reply = ""
    for chunk in response:
        delta = chunk.choices[0].delta.content
        if delta:
            print(delta, end="", flush=True)
            reply += delta

    print()  # 换行

    # 4️⃣ 把模型回复加入历史
    messages.append({"role": "assistant", "content": reply})

    return reply
ask("你是谁")
```
输出：  
```
我是一个人工智能助手，专门设计以帮助用户解决问题和获取有关信息。很高兴为您服务！如果你有任何疑问或需要帮助，请随意告诉我。
```