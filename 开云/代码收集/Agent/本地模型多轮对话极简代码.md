# Ollama的phi3:latest模型
```
from openai import OpenAI

# 连接本地 Ollama 的 OpenAI 接口（模拟）
client = OpenAI(
    base_url="http://localhost:11434/v1",  # Ollama 默认地址
    api_key="ollama"                       # 这个 key 是假的，ollama 接受任意 key
)

messages = [
    {"role": "system", "content": "你是一个简洁、准确的助手"}
]

def ask(msg):
    global messages

    # 1️⃣ 加入用户输入
    messages.append({"role": "user", "content": msg})

    # 2️⃣ 调用模型
    response = client.chat.completions.create(
        model="phi3:latest",
        messages=messages,   # ✅ 关键：传整个历史
        stream=True
    )

    # 3️⃣ 收集模型回复
    reply = ""
    for chunk in response:
        delta = chunk.choices[0].delta.content
        if delta:
            print(delta, end="", flush=True)
            reply += delta

    print()  # 换行

    # 4️⃣ 把模型回复加入历史
    messages.append({"role": "assistant", "content": reply})

    return reply
ask("你是谁")
ask("你可以帮我什么？我之前问了哪些问题？")
```
输出：  
```
我是一个人工智能助手，专门设计以帮助用户解决问题和获取有关信息。很高兴为您服务！如果你有任何疑问或需要帮助，请随意告诉我。
我可以为您提埃益性的信息、解答方差广泛的知识问题，助教新闻或者教程，并帮我实现一些生态基本任务。例如，在过去，我有问题包括：

1. 你能告诉我今天的天气预测吗？
2. Python中代码写法有一些特点请告诉我。
3. 如何为《百年春》这本书撰写一个深度分析？
4. JavaScript生态系统中的前童期和优先程序的设计思想有何不同吗？
5. MongoDB数据库与SQLServer对应地有什么主要不足？

为了继而提供深度分析这一问尴弓问：

6. 我最喜欢的两位作者是谁
7. 他们的写作风格有何体现特点请告诉我。
8. 你猜测未来两十年内两大文学趋势是什么样子将会发生
```  
这个模型2GB左右，不是很智能。
